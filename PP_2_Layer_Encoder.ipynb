{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PP 2 Layer Encoder.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jeIw3TKuSkFv",
        "outputId": "056e5173-3714-42f0-f06e-f587932ab854",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "! nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tue May  7 19:52:31 2019       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 418.56       Driver Version: 410.79       CUDA Version: 10.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   60C    P0    28W /  70W |   1177MiB / 15079MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "imWPY_q-9dCj",
        "colab_type": "code",
        "outputId": "fc5ad834-db31-4065-c284-9b1a9e914073",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!pip install -U -q PyDrive\n",
        "\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "# Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "print('success!')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "success!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_hK82MEcShtP",
        "colab": {}
      },
      "source": [
        "from progressbar import ProgressBar, Percentage, Bar\n",
        "from google.colab import files\n",
        "import torch, pickle, os, sys, random, time, math, copy\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from queue import PriorityQueue"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jofhEDcZSZLH",
        "outputId": "f6c6c0a6-d996-4a21-9325-2d801fc3b8a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "########################### ENTIRE DATASET (WITH BPE) ###########################\n",
        "german = drive.CreateFile({'id': '1KNeZ_WQPUudwlJsg5_kUqPlLjJGBynsn'})\n",
        "german.GetContentFile('./german_bpe.pickle') \n",
        "with open('./german_bpe.pickle', 'rb') as f_in:\n",
        "    german = pickle.load(f_in)\n",
        "    \n",
        "english = drive.CreateFile({'id': '1ObXLocsuZsVGH3MVxSUdDBpiMlgBqVP7'})\n",
        "english.GetContentFile('./english_bpe.pickle') \n",
        "with open('./english_bpe.pickle', 'rb') as f_in:\n",
        "    english = pickle.load(f_in)\n",
        "    \n",
        "training_data = [[german['train'][i], english['train'][i]] for i in range(len(german['train']))]\n",
        "validation_data = [[german['dev'][i], english['dev'][i]] for i in range(len(german['dev']))]\n",
        "\n",
        "max_len_train = len(max(german['train'], key=len))\n",
        "max_len_valid = len(max(german['dev'], key=len))\n",
        "\n",
        "print(max_len_train, max_len_valid)\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "906 281\n",
            "cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Ji-pU6kFSVL4",
        "colab": {}
      },
      "source": [
        "def to_padded_tensor(batch):\n",
        "    max_len_src = max([len(sent['source']) for sent in batch])  \n",
        "    max_len_trg = max([len(sent['target']) for sent in batch])\n",
        "    source_lengths = torch.zeros(len(batch), dtype=torch.int64).cpu()\n",
        "\n",
        "    for i, sent in enumerate(batch):\n",
        "        source_lengths[i] = len(sent['source'])\n",
        "        dif_src = max_len_src - len(sent['source'])\n",
        "        dif_trg = max_len_trg - len(sent['target'])\n",
        "\n",
        "        if dif_src > 0:\n",
        "            pad_list_src = [0 for d in range(dif_src)]\n",
        "            sent['source'].extend(pad_list_src)\n",
        "\n",
        "        if dif_trg > 0:\n",
        "            pad_list_trg = [0 for d in range(dif_trg)]\n",
        "            sent['target'].extend(pad_list_trg)       \n",
        "    \n",
        "    source_sent_len = max_len_src\n",
        "    target_sent_len = max_len_trg\n",
        "    \n",
        "    batch_size = len(batch)\n",
        "    \n",
        "    source = torch.empty((source_sent_len, batch_size)).long().cpu()    \n",
        "    target = torch.empty((target_sent_len, batch_size)).long().cpu()\n",
        "    \n",
        "#     print(batch[0]['target'])\n",
        "    \n",
        "    for i in range(len(batch)):\n",
        "        source[:,i] = torch.tensor(batch[i]['source'])\n",
        "        target[:,i] = torch.tensor(batch[i]['target'])\n",
        "        \n",
        "    padded_tensor = {\"source\": source.to(device),\n",
        "                    \"target\": target.to(device),\n",
        "                    \"srclen\": source_lengths}\n",
        "    \n",
        "    return padded_tensor"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "HMxoSUgrSMiI",
        "colab": {}
      },
      "source": [
        "def bake_batches(de, en, batch_size=1300, min_len=3, max_len=768, bucket_step=3):\n",
        "    german = copy.deepcopy(de)\n",
        "    english = copy.deepcopy(en)\n",
        "    \n",
        "    buckets = [[] for i in range(0, max_len, bucket_step)]\n",
        "    bucket_lengths = [0 for i in buckets]\n",
        "    batches = []\n",
        "    \n",
        "    # For every sentence in the dataset, find its corresponding bucket and put it in there, once the bucket\n",
        "    # hits the batch size, ship it off to the batches list\n",
        "    for i in range(len(german)):\n",
        "        sent2sent = {\"source\": german[i],\n",
        "                     \"target\": english[i]}\n",
        "        \n",
        "        # calculate the index of the buckets to put the sentence into, = len(Sentence) // Bucket_step - 1\n",
        "        idx = len(sent2sent['source'])//bucket_step - 1 \n",
        "\n",
        "        if bucket_lengths[idx] + len(sent2sent['source']) > batch_size:\n",
        "            sorted_bucket = sorted(buckets[idx], key=lambda x: len(x['source']), reverse=True)\n",
        "            batches.append(to_padded_tensor(sorted_bucket))\n",
        "            del buckets[idx][:]\n",
        "            buckets[idx].append(sent2sent)\n",
        "            bucket_lengths[idx] = len(sent2sent['source'])\n",
        "        else:\n",
        "            buckets[idx].append(sent2sent)\n",
        "            bucket_lengths[idx] += len(sent2sent['source'])\n",
        "            \n",
        "\n",
        "    # for any remaining buckets that did not get sent off, send them off to batches\n",
        "    for b in buckets:\n",
        "        if b: # if the list has any value in it\n",
        "            sorted_bucket = sorted(b, key=lambda x: len(x['source']), reverse=True)\n",
        "            batches.append(to_padded_tensor(sorted_bucket))\n",
        "            del b[:]\n",
        "    \n",
        "    return batches"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3GP2fk4oTR3_",
        "colab": {}
      },
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_dim, emb_dim, enc_hid_dim, dec_hid_dim, dropout):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.input_dim = input_dim\n",
        "        self.emb_dim = emb_dim\n",
        "        self.enc_hid_dim = enc_hid_dim\n",
        "        self.dec_hid_dim = dec_hid_dim\n",
        "        self.dropout = dropout\n",
        "        \n",
        "        self.embedding = nn.Embedding(input_dim, emb_dim)\n",
        "        \n",
        "        self.rnn = nn.GRU(emb_dim, enc_hid_dim, num_layers=2, bidirectional = True, dropout=0.5)\n",
        "        \n",
        "        self.fc = nn.Linear(enc_hid_dim * 2, dec_hid_dim)\n",
        "        \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, src, src_len):\n",
        "        \n",
        "        #src = [src sent len, batch size]\n",
        "        #src_len = [src sent len]\n",
        "        \n",
        "        embedded = self.dropout(self.embedding(src))\n",
        "        \n",
        "        #embedded = [src sent len, batch size, emb dim]\n",
        "        \n",
        "        packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded, src_len)\n",
        "        \n",
        "        packed_outputs, hidden = self.rnn(packed_embedded)\n",
        "                     \n",
        "        #packed_outputs is a packed sequence containing all hidden states\n",
        "        #hidden is now from the final non-padded element in the batch\n",
        "            \n",
        "        outputs, _ = nn.utils.rnn.pad_packed_sequence(packed_outputs) \n",
        "            \n",
        "        #outputs is now a non-packed sequence, all hidden states obtained\n",
        "        #  when the input is a pad token are all zeros\n",
        "            \n",
        "        #outputs = [sent len, batch size, hid dim * num directions]\n",
        "        #hidden = [n layers * num directions, batch size, hid dim]\n",
        "        \n",
        "        #hidden is stacked [forward_1, backward_1, forward_2, backward_2, ...]\n",
        "        #outputs are always from the last layer\n",
        "        \n",
        "#         print(hidden.shape)\n",
        "        #hidden [-2, :, : ] is the last of the forwards RNN \n",
        "        #hidden [-1, :, : ] is the last of the backwards RNN\n",
        "        \n",
        "        #initial decoder hidden is final hidden state of the forwards and backwards \n",
        "        #  encoder RNNs fed through a linear layer\n",
        "        hidden = torch.tanh(self.fc(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1)))\n",
        "        \n",
        "        #outputs = [sent len, batch size, enc hid dim * 2]\n",
        "        #hidden = [batch size, dec hid dim]\n",
        "        \n",
        "        return outputs, hidden"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "znY3SLkkTTuH",
        "colab": {}
      },
      "source": [
        "class Attention(nn.Module):\n",
        "    def __init__(self, enc_hid_dim, dec_hid_dim):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.enc_hid_dim = enc_hid_dim\n",
        "        self.dec_hid_dim = dec_hid_dim\n",
        "        \n",
        "        self.attn = nn.Linear((enc_hid_dim * 2) + dec_hid_dim, dec_hid_dim)\n",
        "        self.v = nn.Parameter(torch.rand(dec_hid_dim))\n",
        "        \n",
        "    def forward(self, hidden, encoder_outputs, mask):\n",
        "        \n",
        "        #hidden = [batch size, dec hid dim]\n",
        "        #encoder_outputs = [src sent len, batch size, enc hid dim * 2]\n",
        "        #mask = [batch size, src sent len]\n",
        "        \n",
        "        batch_size = encoder_outputs.shape[1]\n",
        "        src_len = encoder_outputs.shape[0]\n",
        "        \n",
        "        #repeat encoder hidden state src_len times\n",
        "        hidden = hidden.unsqueeze(1).repeat(1, src_len, 1)\n",
        "        \n",
        "        encoder_outputs = encoder_outputs.permute(1, 0, 2)\n",
        "        \n",
        "        #hidden = [batch size, src sent len, dec hid dim]\n",
        "        #encoder_outputs = [batch size, src sent len, enc hid dim * 2]\n",
        "        \n",
        "        energy = torch.tanh(self.attn(torch.cat((hidden, encoder_outputs), dim = 2))) \n",
        "        \n",
        "        #energy = [batch size, src sent len, dec hid dim]\n",
        "                \n",
        "        energy = energy.permute(0, 2, 1)\n",
        "        \n",
        "        #energy = [batch size, dec hid dim, src sent len]\n",
        "        \n",
        "        #v = [dec hid dim]\n",
        "        \n",
        "        v = self.v.repeat(batch_size, 1).unsqueeze(1)\n",
        "        \n",
        "        #v = [batch size, 1, dec hid dim]\n",
        "            \n",
        "        attention = torch.bmm(v, energy).squeeze(1)\n",
        "        \n",
        "        #attention = [batch size, src sent len]\n",
        "        \n",
        "        attention = attention.masked_fill(mask == 0, -1e10)\n",
        "        \n",
        "        return F.softmax(attention, dim = 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2k6c85_lTV13",
        "colab": {}
      },
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self, output_dim, emb_dim, enc_hid_dim, dec_hid_dim, dropout, attention):\n",
        "        super().__init__()\n",
        "\n",
        "        self.emb_dim = emb_dim\n",
        "        self.enc_hid_dim = enc_hid_dim\n",
        "        self.dec_hid_dim = dec_hid_dim\n",
        "        self.output_dim = output_dim\n",
        "        self.dropout = dropout\n",
        "        self.attention = attention\n",
        "        \n",
        "        self.embedding = nn.Embedding(output_dim, emb_dim)\n",
        "        \n",
        "        self.rnn = nn.GRU((enc_hid_dim * 2) + emb_dim, dec_hid_dim)#, num_layers=2, dropout=0.3)\n",
        "        \n",
        "        self.out = nn.Linear((enc_hid_dim * 2) + dec_hid_dim + emb_dim, output_dim)\n",
        "        \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, input, hidden, encoder_outputs, mask):\n",
        "             \n",
        "        #input = [batch size]\n",
        "        #hidden = [batch size, dec hid dim]\n",
        "        #encoder_outputs = [src sent len, batch size, enc hid dim * 2]\n",
        "        #mask = [batch size, src sent len]\n",
        "        \n",
        "        input = input.unsqueeze(0)\n",
        "        \n",
        "        #input = [1, batch size]\n",
        "        \n",
        "        embedded = self.dropout(self.embedding(input))\n",
        "        \n",
        "        #embedded = [1, batch size, emb dim]\n",
        "        \n",
        "        a = self.attention(hidden, encoder_outputs, mask)\n",
        "                \n",
        "        #a = [batch size, src sent len]\n",
        "        \n",
        "        a = a.unsqueeze(1)\n",
        "        \n",
        "        #a = [batch size, 1, src sent len]\n",
        "        \n",
        "        encoder_outputs = encoder_outputs.permute(1, 0, 2)\n",
        "        \n",
        "        #encoder_outputs = [batch size, src sent len, enc hid dim * 2]\n",
        "        \n",
        "        weighted = torch.bmm(a, encoder_outputs)\n",
        "        \n",
        "        #weighted = [batch size, 1, enc hid dim * 2]\n",
        "        \n",
        "        weighted = weighted.permute(1, 0, 2)\n",
        "        \n",
        "        #weighted = [1, batch size, enc hid dim * 2]\n",
        "        \n",
        "        rnn_input = torch.cat((embedded, weighted), dim = 2)\n",
        "#         print(hidden.shape)\n",
        "        \n",
        "        #rnn_input = [1, batch size, (enc hid dim * 2) + emb dim]\n",
        "            \n",
        "        output, hidden = self.rnn(rnn_input, hidden.unsqueeze(0))\n",
        "        \n",
        "        #output = [sent len, batch size, dec hid dim * n directions]\n",
        "        #hidden = [n layers * n directions, batch size, dec hid dim]\n",
        "        \n",
        "        #sent len, n layers and n directions will always be 1 in this decoder, therefore:\n",
        "        #output = [1, batch size, dec hid dim]\n",
        "        #hidden = [1, batch size, dec hid dim]\n",
        "        #this also means that output == hidden\n",
        "        assert (output == hidden).all()\n",
        "        \n",
        "        embedded = embedded.squeeze(0)\n",
        "        output = output.squeeze(0)\n",
        "        weighted = weighted.squeeze(0)\n",
        "        \n",
        "        output = self.out(torch.cat((output, weighted, embedded), dim = 1))\n",
        "        \n",
        "        #output = [bsz, output dim]\n",
        "        \n",
        "        return output, hidden.squeeze(0), a.squeeze(1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "rMytQscpTXqn",
        "colab": {}
      },
      "source": [
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self, encoder, decoder, pad_idx, sos_idx, eos_idx, device):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.pad_idx = pad_idx\n",
        "        self.sos_idx = sos_idx\n",
        "        self.eos_idx = eos_idx\n",
        "        self.device = device\n",
        "        \n",
        "    def create_mask(self, src):\n",
        "        mask = (src != self.pad_idx).permute(1, 0)\n",
        "        return mask\n",
        "        \n",
        "    def forward(self, src, src_len, trg, teacher_forcing_ratio = 1):\n",
        "        \n",
        "        #src = [src sent len, batch size]\n",
        "        #src_len = [batch size]\n",
        "        #trg = [trg sent len, batch size]\n",
        "        #teacher_forcing_ratio is probability to use teacher forcing\n",
        "        #e.g. if teacher_forcing_ratio is 0.75 we use teacher forcing 75% of the time\n",
        "        \n",
        "        if trg is None:\n",
        "            assert teacher_forcing_ratio == 0, \"Must be zero during inference\"\n",
        "            inference = True\n",
        "            trg = torch.zeros((100, src.shape[1])).long().fill_(self.sos_idx).to(src.device)\n",
        "        else:\n",
        "            inference = False\n",
        "            \n",
        "        batch_size = src.shape[1]\n",
        "        max_len = trg.shape[0]\n",
        "        trg_vocab_size = self.decoder.output_dim\n",
        "        \n",
        "        #tensor to store decoder outputs\n",
        "        outputs = torch.zeros(max_len, batch_size, trg_vocab_size).to(self.device)\n",
        "        \n",
        "        #tensor to store attention\n",
        "        attentions = torch.zeros(max_len, batch_size, src.shape[0]).to(self.device)\n",
        "        \n",
        "        #encoder_outputs is all hidden states of the input sequence, back and forwards\n",
        "        #hidden is the final forward and backward hidden states, passed through a linear layer\n",
        "        encoder_outputs, hidden = self.encoder(src, src_len)\n",
        "                \n",
        "        #first input to the decoder is the <sos> tokens\n",
        "        output = trg[0,:]\n",
        "        \n",
        "        mask = self.create_mask(src)\n",
        "#         print(hidden.shape)\n",
        "                \n",
        "        #mask = [batch size, src sent len]\n",
        "                \n",
        "        for t in range(1, max_len):\n",
        "            output, hidden, attention = self.decoder(output, hidden, encoder_outputs, mask)\n",
        "            outputs[t] = output\n",
        "            attentions[t] = attention\n",
        "            teacher_force = random.random() < teacher_forcing_ratio\n",
        "            top1 = output.max(1)[1]\n",
        "            output = (trg[t] if teacher_force else top1)\n",
        "            if inference and output.item() == self.eos_idx:\n",
        "                return outputs[:t], attentions[:t]\n",
        "            \n",
        "        return outputs, attentions"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "l7zaiWuLTaJ4",
        "colab": {}
      },
      "source": [
        "def train(model, iterator, optimizer, criterion, clip):\n",
        "    \n",
        "    model.train()\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    \n",
        "    for i, batch in enumerate(iterator):\n",
        "        \n",
        "        src = batch['source']\n",
        "        src_len = batch['srclen']\n",
        "        trg = batch['target']\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        output, attetion = model(src, src_len, trg)\n",
        "        if i%(len(iterator)//4) == 0: \n",
        "            print( \"batch:\", i)#, \",\", torch.cuda.memory_allocated(device)/1e6, \"MB used\") \n",
        "        \n",
        "        #trg = [trg sent len, batch size]\n",
        "        #output = [trg sent len, batch size, output dim]\n",
        "        \n",
        "        output = output[1:].view(-1, output.shape[-1])\n",
        "        trg = trg[1:].view(-1)\n",
        "        \n",
        "        #trg = [(trg sent len - 1) * batch size]\n",
        "        #output = [(trg sent len - 1) * batch size, output dim]\n",
        "        \n",
        "        loss = criterion(output, trg)\n",
        "        \n",
        "        loss.backward()\n",
        "        \n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "        \n",
        "        optimizer.step()\n",
        "        \n",
        "        epoch_loss += loss.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "i-ZvNqg_TbqY",
        "colab": {}
      },
      "source": [
        "def evaluate(model, iterator, criterion):\n",
        "    \n",
        "    model.eval()\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    \n",
        "    with torch.no_grad():\n",
        "    \n",
        "        for i, batch in enumerate(iterator):\n",
        "            \n",
        "            src = batch['source']\n",
        "            src_len = batch['srclen']\n",
        "            trg = batch['target']\n",
        "\n",
        "            output, attention = model(src, src_len, trg, 0) #turn off teacher forcing\n",
        "\n",
        "            #trg = [trg sent len, batch size]\n",
        "            #output = [trg sent len, batch size, output dim]\n",
        "\n",
        "            output = output[1:].view(-1, output.shape[-1])\n",
        "            trg = trg[1:].view(-1)\n",
        "\n",
        "            #trg = [(trg sent len - 1) * batch size]\n",
        "            #output = [(trg sent len - 1) * batch size, output dim]\n",
        "\n",
        "            loss = criterion(output, trg)\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "sjlae7-bThBQ",
        "colab": {}
      },
      "source": [
        "def init_weights(m):\n",
        "    for name, param in m.named_parameters():\n",
        "        if 'weight' in name:\n",
        "            nn.init.normal_(param.data, mean=0, std=0.01)\n",
        "        else:\n",
        "            nn.init.constant_(param.data, 0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zvRkeOcsTnQv",
        "colab": {}
      },
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "SmMFvmB4ToqX",
        "colab": {}
      },
      "source": [
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VUilz_SnVAkX",
        "outputId": "87da1cd2-113e-452e-afd4-893c8412abdf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "def average_sentence_size(german, desired_batch_size=128):\n",
        "    summation = 0\n",
        "    for i in german['train']:\n",
        "        summation += len(i)\n",
        "    avg_tok_sent = summation/len(german['train'])\n",
        "    \n",
        "    print(\"To get an average batch size of\", desired_batch_size, \"Use a batch_size value of:\", int(desired_batch_size*avg_tok_sent))\n",
        "    \n",
        "average_sentence_size(german, desired_batch_size=100)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "To get an average batch size of 100 Use a batch_size value of: 2717\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d9pYxzuI1s7F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def write_to_drive(filename):\n",
        "    from googleapiclient.discovery import build\n",
        "    drive_service = build('drive', 'v3')\n",
        "\n",
        "    from googleapiclient.http import MediaFileUpload\n",
        "\n",
        "    file_metadata = {\n",
        "      'name': filename\n",
        "    }\n",
        "    media = MediaFileUpload(filename, \n",
        "                            resumable=True)\n",
        "    created = drive_service.files().create(body=file_metadata,\n",
        "                                           media_body=media,\n",
        "                                           fields='id').execute()\n",
        "    print('File ID: {}'.format(created.get('id')))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "bx1wjCwnTrdn",
        "outputId": "f4908934-7f2a-489e-815d-4f339fdb38e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "N_EPOCHS = 30\n",
        "CLIP = 1\n",
        "\n",
        "INPUT_DIM = len(german['idx2word'])\n",
        "OUTPUT_DIM = len(english['idx2word'])\n",
        "ENC_EMB_DIM = 256\n",
        "DEC_EMB_DIM = 256\n",
        "ENC_HID_DIM = 512\n",
        "DEC_HID_DIM = 512\n",
        "ENC_DROPOUT = 0.5\n",
        "DEC_DROPOUT = 0.5\n",
        "PAD_IDX = 0\n",
        "SOS_IDX = 2\n",
        "EOS_IDX = 3\n",
        "\n",
        "attn = Attention(ENC_HID_DIM, DEC_HID_DIM)\n",
        "enc = Encoder(INPUT_DIM, ENC_EMB_DIM, ENC_HID_DIM, DEC_HID_DIM, ENC_DROPOUT)\n",
        "dec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, ENC_HID_DIM, DEC_HID_DIM, DEC_DROPOUT, attn)\n",
        "\n",
        "model = Seq2Seq(enc, dec, PAD_IDX, SOS_IDX, EOS_IDX, device).to(device)\n",
        "\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')\n",
        "\n",
        "model.apply(init_weights)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(ignore_index = PAD_IDX)\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "\n",
        "best_train_loss = float('inf')\n",
        "bad_epoch_cnt = 0\n",
        "\n",
        "results = {\"hyperparams\": (ENC_EMB_DIM, DEC_HID_DIM),\n",
        "           \"train_loss\": [],\n",
        "           \"valid_loss\": [],\n",
        "           \"train_ppl\": [],\n",
        "           \"valid_ppl\": []}\n",
        "\n",
        "valid_batches = bake_batches(german['dev'], english['dev'], batch_size=2400, max_len=max_len_valid)\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "    random.shuffle(training_data)\n",
        "\n",
        "    de_shuffled_td = [td[0] for td in training_data]\n",
        "    en_shuffled_td = [td[1] for td in training_data]\n",
        "\n",
        "    print(\"Baking batches...\", end= \" \")\n",
        "    train_batches = bake_batches(de_shuffled_td, en_shuffled_td, batch_size=2800, max_len=max_len_train)\n",
        "    print(\"Done.\")\n",
        "    \n",
        "    start_time = time.time()\n",
        "\n",
        "    train_loss = train(model, train_batches, optimizer, criterion, CLIP)\n",
        "    valid_loss = evaluate(model, valid_batches, criterion)\n",
        "\n",
        "    end_time = time.time()\n",
        "\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "    \n",
        "    print(\"Validation loss has not improved in\", bad_epoch_cnt, \"epochs\")        \n",
        "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f}')\n",
        "    \n",
        "    # Save the last epoch over the checkpoint\n",
        "    checkpoint = {}\n",
        "    checkpoint['state_dict'] = model.state_dict()\n",
        "    checkpoint['optimizer'] = optimizer.state_dict()\n",
        "    checkpoint['epoch'] = epoch\n",
        "    file_name = 'last_checkpoint.pth'        \n",
        "    torch.save(checkpoint, file_name)\n",
        "    write_to_drive(file_name)\n",
        "    \n",
        "    results['train_loss'].append(train_loss)\n",
        "    results['valid_loss'].append(valid_loss)\n",
        "    results['train_ppl'].append(math.exp(train_loss))\n",
        "    results['valid_ppl'].append(math.exp(valid_loss))\n",
        "    "
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The model has 37,792,291 trainable parameters\n",
            "Baking batches... Done.\n",
            "batch: 0\n",
            "batch: 1\n",
            "batch: 2\n",
            "batch: 3\n",
            "Validation loss has not improved in 0 epochs\n",
            "Epoch: 01 | Time: 0m 24s\n",
            "\tTrain Loss: 9.346 | Train PPL: 11455.372\n",
            "\t Val. Loss: 9.264 |  Val. PPL: 10546.362\n",
            "File ID: 1cr8aALzebBlNSTHv7DI-_xGrY9tBwZfm\n",
            "Baking batches... Done.\n",
            "batch: 0\n",
            "batch: 1\n",
            "batch: 2\n",
            "batch: 3\n",
            "Validation loss has not improved in 0 epochs\n",
            "Epoch: 02 | Time: 0m 25s\n",
            "\tTrain Loss: 7.942 | Train PPL: 2813.712\n",
            "\t Val. Loss: 12.040 |  Val. PPL: 169388.496\n",
            "File ID: 1VWq_Mr5ugtUPDR2qFi5webKi_Qr1QRKl\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DPx-91qcYAR_",
        "colab": {}
      },
      "source": [
        "target_file = drive.CreateFile({'id': '115tf274P47ZyBj1EdfeOpPWIK6hDwCnl'})\n",
        "target_file.GetContentFile('./target.out') \n",
        "    \n",
        "source_file = drive.CreateFile({'id': '1gAvrzv6I6Y6Qr2j1Oah4lz4eIgHdiVW7'})\n",
        "source_file.GetContentFile('./source.out') \n",
        "    \n",
        "def sample_net(net, test_de):    \n",
        "    preds = []\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for i, sent in enumerate(test_de):\n",
        "            src = torch.LongTensor(sent).unsqueeze(1).to(device) \n",
        "            src_len = torch.LongTensor([len(sent)])\n",
        "    \n",
        "            output, _ = net(src, src_len, None, 0)\n",
        " \n",
        "            pred = torch.argmax(output, dim=2)            \n",
        "            preds.append(pred)\n",
        "\n",
        "    return preds\n",
        "   \n",
        "# INPUT_DIM = len(german['idx2word'])\n",
        "# OUTPUT_DIM = len(english['idx2word'])\n",
        "# ENC_EMB_DIM = 256\n",
        "# DEC_EMB_DIM = 256\n",
        "# ENC_HID_DIM = 512\n",
        "# DEC_HID_DIM = 512\n",
        "# ENC_DROPOUT = 0.3\n",
        "# DEC_DROPOUT = 0.3\n",
        "# PAD_IDX = 0\n",
        "# SOS_IDX = 2\n",
        "# EOS_IDX = 3\n",
        "\n",
        "# attn = Attention(ENC_HID_DIM, DEC_HID_DIM)\n",
        "# enc = Encoder(INPUT_DIM, ENC_EMB_DIM, ENC_HID_DIM, DEC_HID_DIM, ENC_DROPOUT)\n",
        "# dec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, ENC_HID_DIM, DEC_HID_DIM, DEC_DROPOUT, attn)\n",
        "\n",
        "# model = Seq2Seq(enc, dec, PAD_IDX, SOS_IDX, EOS_IDX, device).to(device)\n",
        "# model.load_state_dict(torch.load(\"packed-padded-a.pt\"))\n",
        "\n",
        "predictions = sample_net(model, german['dev'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "pOMz7UZRqKb4",
        "colab": {}
      },
      "source": [
        "def print_samples(predictions):\n",
        "    preds_tokenized = []  \n",
        "    \n",
        "    for pred in predictions:\n",
        "        pred_sent = []\n",
        "        w=1\n",
        "        while w < len(pred) and pred[w].item() != 3:\n",
        "            idx = pred[w].item()\n",
        "            pred_sent.append(english['idx2word'][idx])\n",
        "            w+=1\n",
        "        preds_tokenized.append(pred_sent)\n",
        "    \n",
        "    with open('pred.out', 'w') as f:\n",
        "        for sent in preds_tokenized:\n",
        "            y = \" \".join(sent)\n",
        "            f.write(y + '\\n')\n",
        "            \n",
        "print_samples(predictions)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "OupV3yL-qPua",
        "colab": {}
      },
      "source": [
        "!sed -r -i 's/(@@ )|(@@ ?$)//g' pred.out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "L6QYqRnsqnHx",
        "outputId": "ff48b12e-4d6c-4618-c015-4304d3bd3b39",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "!git clone https://github.com/moses-smt/mosesdecoder.git\n",
        "!pip install sacrebleu\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'mosesdecoder' already exists and is not an empty directory.\n",
            "Requirement already satisfied: sacrebleu in /usr/local/lib/python3.6/dist-packages (1.3.2)\n",
            "Requirement already satisfied: typing in /usr/local/lib/python3.6/dist-packages (from sacrebleu) (3.6.6)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ILn097VIqgX5",
        "outputId": "f662b006-dbb2-46d5-c9aa-f5d4af02d217",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "%%shell\n",
        "# !/bin/bash\n",
        "\n",
        "# This is a reference to the gold translations from the dev set\n",
        "REFERENCE_FILE=\"target.out\"\n",
        "\n",
        "# XXX: Change the following line to point to your model's output!\n",
        "TRANSLATED_FILE=\"pred.out\"\n",
        "\n",
        "# The model output is expected to be in a tokenized form. Note, that if you\n",
        "# tokenized your inputs to the model, then simply joined each output token with\n",
        "# whitespace you should get tokenized outputs from your model.\n",
        "# i.e. each output token is separate by whitespace\n",
        "# e.g. \"My model 's output is interesting .\"\n",
        "perl \"mosesdecoder/scripts/tokenizer/detokenizer.perl\" -l en < \"$TRANSLATED_FILE\" > \"$TRANSLATED_FILE.detok\"\n",
        "\n",
        "PARAMS=(\"-tok\" \"intl\" \"-l\" \"de-en\" \"$REFERENCE_FILE\")\n",
        "sacrebleu \"${PARAMS[@]}\" < \"$TRANSLATED_FILE.detok\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Detokenizer Version $Revision: 4134 $\n",
            "Language: en\n",
            "BLEU+case.mixed+lang.de-en+numrefs.1+smooth.exp+tok.intl+version.1.3.2 = 19.4 52.0/25.1/13.8/7.9 (BP = 1.000 ratio = 1.015 hyp_len = 163383 ref_len = 160956)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              ""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LP9p44_1qjTR",
        "colab": {}
      },
      "source": [
        "torch.save(model.state_dict(), 'model-bleu-17.5.pt')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "MHWzTddZrbjo",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}