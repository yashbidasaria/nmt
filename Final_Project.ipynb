{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 323
    },
    "colab_type": "code",
    "id": "F6YKpEtz2Wsk",
    "outputId": "33e62316-4512-49ee-908c-7ef3fdffacdb"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'nvidia-smi' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "! nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Ai-duA696vlS",
    "outputId": "2b65acfd-0552-4edf-acda-49f12c8623a9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success!\n"
     ]
    }
   ],
   "source": [
    "!pip install -U -q PyDrive\n",
    "\n",
    "from google.colab import files\n",
    "from pydrive.auth import GoogleAuth\n",
    "from pydrive.drive import GoogleDrive\n",
    "from google.colab import auth\n",
    "from oauth2client.client import GoogleCredentials\n",
    "# Authenticate and create the PyDrive client.\n",
    "auth.authenticate_user()\n",
    "gauth = GoogleAuth()\n",
    "gauth.credentials = GoogleCredentials.get_application_default()\n",
    "drive = GoogleDrive(gauth)\n",
    "print('success!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "ZiVfPF4F90za",
    "outputId": "d377e81b-7e47-4e85-dc65-e3a2b8ceb4f4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "from progressbar import ProgressBar, Percentage, Bar\n",
    "import torch, pickle, os, sys, random, time, math, copy\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# german = drive.CreateFile({'id': '1I0_go5RhzEg2CkbpZgx8a6h4hA9qNeyY'})\n",
    "# german.GetContentFile('./german_no_pad_sorted.pickle') \n",
    "# with open('./german_no_pad_sorted.pickle', 'rb') as f_in:\n",
    "#     german = pickle.load(f_in)\n",
    "    \n",
    "# english = drive.CreateFile({'id': '1Tb0aYVfkj3YyXXTxWRkvDO7T__ovng1Q'})\n",
    "# english.GetContentFile('./english_no_pad_sorted.pickle') \n",
    "# with open('./english_no_pad_sorted.pickle', 'rb') as f_in:\n",
    "#     english = pickle.load(f_in)    \n",
    "    \n",
    "german = drive.CreateFile({'id': '10epaM5VzSskc0xkriD0YN_a0Mg3-o1bg'})\n",
    "german.GetContentFile('./german_no_pad_sorted_5k.pickle') \n",
    "with open('./german_no_pad_sorted_5k.pickle', 'rb') as f_in:\n",
    "    german = pickle.load(f_in)\n",
    "\n",
    "english = drive.CreateFile({'id': '15P0N9sLAIPyxF0Uhgx-01P2s-xOLp6xb'})\n",
    "english.GetContentFile('./english_no_pad_sorted_5k.pickle') \n",
    "with open('./english_no_pad_sorted_5k.pickle', 'rb') as f_in:\n",
    "    english = pickle.load(f_in)\n",
    "\n",
    "\n",
    "training_data = [[german['train'][i], english['train'][i]] for i in range(len(german['train']))]\n",
    "validation_data = [[german['dev'][i], english['dev'][i]] for i in range(len(german['dev']))]\n",
    "\n",
    "max_len_train = len(max(german['train'], key=len))\n",
    "max_len_valid = len(max(german['dev'], key=len))\n",
    "\n",
    "print(max_len_train, max_len_valid)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pxfBDiABDVNp"
   },
   "outputs": [],
   "source": [
    "def to_padded_tensor(batch):\n",
    "    max_len_src = max([len(sent['source']) for sent in batch])  \n",
    "    max_len_trg = max([len(sent['target']) for sent in batch])\n",
    "\n",
    "    for sent in batch:\n",
    "        dif_src = max_len_src - len(sent['source'])\n",
    "        dif_trg = max_len_trg - len(sent['target'])\n",
    "\n",
    "        if dif_src > 0:\n",
    "            pad_list_src = [0 for d in range(dif_src)]\n",
    "            sent['source'].extend(pad_list_src)\n",
    "\n",
    "        if dif_trg > 0:\n",
    "            pad_list_trg = [0 for d in range(dif_trg)]\n",
    "            sent['target'].extend(pad_list_trg)       \n",
    "    \n",
    "    source_sent_len = max_len_src\n",
    "    target_sent_len = max_len_trg\n",
    "    \n",
    "    batch_size = len(batch)\n",
    "    \n",
    "    source = torch.empty((source_sent_len, batch_size)).long().cpu()    \n",
    "    target = torch.empty((target_sent_len, batch_size)).long().cpu()\n",
    "    \n",
    "#     print(batch[0]['target'])\n",
    "    \n",
    "    for i in range(len(batch)):\n",
    "        source[:,i] = torch.tensor(batch[i]['source'])\n",
    "        target[:,i] = torch.tensor(batch[i]['target'])\n",
    "        \n",
    "    padded_tensor = {\"source\": source.to(device),\n",
    "                    \"target\": target.to(device)}\n",
    "    \n",
    "    return padded_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iQAoZvykDStp"
   },
   "outputs": [],
   "source": [
    "def bake_batches(de, en, batch_size=1300, min_len=3, max_len=768, bucket_step=3):\n",
    "    german = copy.deepcopy(de)\n",
    "    english = copy.deepcopy(en)\n",
    "    \n",
    "    buckets = [[] for i in range(0, max_len, bucket_step)]\n",
    "    bucket_lengths = [0 for i in buckets]\n",
    "    batches = []\n",
    "    \n",
    "    # For every sentence in the dataset, find its corresponding bucket and put it in there, once the bucket\n",
    "    # hits the batch size, ship it off to the batches list\n",
    "    for i in range(len(german)):\n",
    "        sent2sent = {\"source\": german[i],\n",
    "                     \"target\": english[i]}\n",
    "        \n",
    "        # calculate the index of the buckets to put the sentence into, = len(Sentence) // Bucket_step - 1\n",
    "        idx = len(sent2sent['source'])//bucket_step - 1\n",
    "        \n",
    "        if bucket_lengths[idx] + len(sent2sent['source']) > batch_size:\n",
    "            batches.append(to_padded_tensor(buckets[idx][:]))\n",
    "            del buckets[idx][:]\n",
    "            buckets[idx].append(sent2sent)\n",
    "            bucket_lengths[idx] = len(sent2sent['source'])\n",
    "        else:\n",
    "            buckets[idx].append(sent2sent)\n",
    "            bucket_lengths[idx] += len(sent2sent['source'])\n",
    "            \n",
    "\n",
    "    # for any remaining buckets that did not get sent off, send them off to batches\n",
    "    for b in buckets:\n",
    "        if b: # if the list has any value in it\n",
    "            batches.append(to_padded_tensor(b[:]))\n",
    "            del b[:]\n",
    "    \n",
    "    return batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GZX5hRdP2fHv"
   },
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, emb_dim, enc_hid_dim, dec_hid_dim, dropout):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.input_dim = input_dim\n",
    "        self.emb_dim = emb_dim\n",
    "        self.enc_hid_dim = enc_hid_dim\n",
    "        self.dec_hid_dim = dec_hid_dim\n",
    "        self.dropout = dropout\n",
    "        \n",
    "        self.embedding = nn.Embedding(input_dim, emb_dim)\n",
    "        \n",
    "        self.rnn = nn.GRU(emb_dim, enc_hid_dim, bidirectional = True)\n",
    "        \n",
    "        self.fc = nn.Linear(enc_hid_dim * 2, dec_hid_dim)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, src):\n",
    "        \n",
    "        #src = [src sent len, batch size]\n",
    "        \n",
    "        embedded = self.dropout(self.embedding(src))\n",
    "        \n",
    "        #embedded = [src sent len, batch size, emb dim]\n",
    "        \n",
    "        outputs, hidden = self.rnn(embedded)\n",
    "                \n",
    "        #outputs = [src sent len, batch size, hid dim * num directions]\n",
    "        #hidden = [n layers * num directions, batch size, hid dim]\n",
    "        \n",
    "        #hidden is stacked [forward_1, backward_1, forward_2, backward_2, ...]\n",
    "        #outputs are always from the last layer\n",
    "        \n",
    "        #hidden [-2, :, : ] is the last of the forwards RNN \n",
    "        #hidden [-1, :, : ] is the last of the backwards RNN\n",
    "        \n",
    "        #initial decoder hidden is final hidden state of the forwards and backwards \n",
    "        #  encoder RNNs fed through a linear layer\n",
    "        hidden = torch.tanh(self.fc(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1)))\n",
    "        \n",
    "        #outputs = [src sent len, batch size, enc hid dim * 2]\n",
    "        #hidden = [batch size, dec hid dim]\n",
    "        \n",
    "        return outputs, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rL9QXs3xYoOn"
   },
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    def __init__(self, enc_hid_dim, dec_hid_dim):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.enc_hid_dim = enc_hid_dim\n",
    "        self.dec_hid_dim = dec_hid_dim\n",
    "        \n",
    "        self.attn = nn.Linear((enc_hid_dim * 2) + dec_hid_dim, dec_hid_dim)\n",
    "        self.v = nn.Parameter(torch.rand(dec_hid_dim))\n",
    "        \n",
    "    def forward(self, hidden, encoder_outputs):\n",
    "        \n",
    "        #hidden = [batch size, dec hid dim]\n",
    "        #encoder_outputs = [src sent len, batch size, enc hid dim * 2]\n",
    "        \n",
    "        batch_size = encoder_outputs.shape[1]\n",
    "        src_len = encoder_outputs.shape[0]\n",
    "        \n",
    "        #repeat encoder hidden state src_len times\n",
    "        hidden = hidden.unsqueeze(1).repeat(1, src_len, 1)\n",
    "        \n",
    "        encoder_outputs = encoder_outputs.permute(1, 0, 2)\n",
    "        \n",
    "        #hidden = [batch size, src sent len, dec hid dim]\n",
    "        #encoder_outputs = [batch size, src sent len, enc hid dim * 2]\n",
    "        \n",
    "        energy = torch.tanh(self.attn(torch.cat((hidden, encoder_outputs), dim = 2))) \n",
    "        \n",
    "        #energy = [batch size, src sent len, dec hid dim]\n",
    "        \n",
    "        energy = energy.permute(0, 2, 1)\n",
    "        \n",
    "        #energy = [batch size, dec hid dim, src sent len]\n",
    "        \n",
    "        #v = [dec hid dim]\n",
    "        \n",
    "        v = self.v.repeat(batch_size, 1).unsqueeze(1)\n",
    "        \n",
    "        #v = [batch size, 1, dec hid dim]\n",
    "                \n",
    "        attention = torch.bmm(v, energy).squeeze(1)\n",
    "        \n",
    "        #attention= [batch size, src len]\n",
    "        \n",
    "        return F.softmax(attention, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WoiZeHuP4fPW"
   },
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, output_dim, emb_dim, enc_hid_dim, dec_hid_dim, dropout, attention):\n",
    "        super().__init__()\n",
    "\n",
    "        self.emb_dim = emb_dim\n",
    "        self.enc_hid_dim = enc_hid_dim\n",
    "        self.dec_hid_dim = dec_hid_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.dropout = dropout\n",
    "        self.attention = attention\n",
    "        \n",
    "        self.embedding = nn.Embedding(output_dim, emb_dim)\n",
    "        \n",
    "        self.rnn = nn.GRU((enc_hid_dim * 2) + emb_dim, dec_hid_dim)\n",
    "        \n",
    "        self.out = nn.Linear((enc_hid_dim * 2) + dec_hid_dim + emb_dim, output_dim)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, input, hidden, encoder_outputs):\n",
    "             \n",
    "        #input = [batch size]\n",
    "        #hidden = [batch size, dec hid dim]\n",
    "        #encoder_outputs = [src sent len, batch size, enc hid dim * 2]\n",
    "        \n",
    "        input = input.unsqueeze(0)\n",
    "        \n",
    "        #input = [1, batch size]\n",
    "        \n",
    "        embedded = self.dropout(self.embedding(input))\n",
    "        \n",
    "        #embedded = [1, batch size, emb dim]\n",
    "        \n",
    "        a = self.attention(hidden, encoder_outputs)\n",
    "                \n",
    "        #a = [batch size, src len]\n",
    "        \n",
    "        a = a.unsqueeze(1)\n",
    "        \n",
    "        #a = [batch size, 1, src len]\n",
    "        \n",
    "        encoder_outputs = encoder_outputs.permute(1, 0, 2)\n",
    "        \n",
    "        #encoder_outputs = [batch size, src sent len, enc hid dim * 2]\n",
    "        \n",
    "        weighted = torch.bmm(a, encoder_outputs)\n",
    "        \n",
    "        #weighted = [batch size, 1, enc hid dim * 2]\n",
    "        \n",
    "        weighted = weighted.permute(1, 0, 2)\n",
    "        \n",
    "        #weighted = [1, batch size, enc hid dim * 2]\n",
    "        \n",
    "        rnn_input = torch.cat((embedded, weighted), dim = 2)\n",
    "        \n",
    "        #rnn_input = [1, batch size, (enc hid dim * 2) + emb dim]\n",
    "            \n",
    "        output, hidden = self.rnn(rnn_input, hidden.unsqueeze(0))\n",
    "        \n",
    "        #output = [sent len, batch size, dec hid dim * n directions]\n",
    "        #hidden = [n layers * n directions, batch size, dec hid dim]\n",
    "        \n",
    "        #sent len, n layers and n directions will always be 1 in this decoder, therefore:\n",
    "        #output = [1, batch size, dec hid dim]\n",
    "        #hidden = [1, batch size, dec hid dim]\n",
    "        #this also means that output == hidden\n",
    "        assert (output == hidden).all()\n",
    "        \n",
    "        embedded = embedded.squeeze(0)\n",
    "        output = output.squeeze(0)\n",
    "        weighted = weighted.squeeze(0)\n",
    "        \n",
    "        output = self.out(torch.cat((output, weighted, embedded), dim = 1))\n",
    "        \n",
    "        #output = [bsz, output dim]\n",
    "        \n",
    "        return output, hidden.squeeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mxmqAe9uKTN-"
   },
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder, device):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.device = device\n",
    "        \n",
    "    def forward(self, src, trg, teacher_forcing_ratio = 0.5):\n",
    "        \n",
    "        #src = [src sent len, batch size]\n",
    "        #trg = [trg sent len, batch size]\n",
    "        #teacher_forcing_ratio is probability to use teacher forcing\n",
    "        #e.g. if teacher_forcing_ratio is 0.75 we use teacher forcing 75% of the time\n",
    "        \n",
    "        batch_size = src.shape[1]\n",
    "        max_len = trg.shape[0]\n",
    "        trg_vocab_size = self.decoder.output_dim\n",
    "        \n",
    "        #tensor to store decoder outputs\n",
    "        outputs = torch.zeros(max_len, batch_size, trg_vocab_size).to(self.device)\n",
    "        \n",
    "        #encoder_outputs is all hidden states of the input sequence, back and forwards\n",
    "        #hidden is the final forward and backward hidden states, passed through a linear layer\n",
    "        encoder_outputs, hidden = self.encoder(src)\n",
    "                \n",
    "        #first input to the decoder is the <sos> tokens\n",
    "        output = trg[0,:]\n",
    "        \n",
    "        for t in range(1, max_len):\n",
    "            output, hidden = self.decoder(output, hidden, encoder_outputs)\n",
    "            outputs[t] = output\n",
    "            teacher_force = random.random() < teacher_forcing_ratio\n",
    "            top1 = output.max(1)[1]\n",
    "            output = (trg[t] if teacher_force else top1)\n",
    "\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XdZnmvpncyZ3"
   },
   "outputs": [],
   "source": [
    "INPUT_DIM = len(SRC.vocab)\n",
    "OUTPUT_DIM = len(TRG.vocab)\n",
    "ENC_EMB_DIM = 256\n",
    "DEC_EMB_DIM = 256\n",
    "ENC_HID_DIM = 512\n",
    "DEC_HID_DIM = 512\n",
    "ENC_DROPOUT = 0.5\n",
    "DEC_DROPOUT = 0.5\n",
    "\n",
    "attn = Attention(ENC_HID_DIM, DEC_HID_DIM)\n",
    "enc = Encoder(INPUT_DIM, ENC_EMB_DIM, ENC_HID_DIM, DEC_HID_DIM, ENC_DROPOUT)\n",
    "dec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, ENC_HID_DIM, DEC_HID_DIM, DEC_DROPOUT, attn)\n",
    "\n",
    "model = Seq2Seq(enc, dec, device).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seq2Seq(\n",
       "  (encoder): Encoder(\n",
       "    (embedding): Embedding(7855, 256)\n",
       "    (rnn): GRU(256, 512, bidirectional=True)\n",
       "    (fc): Linear(in_features=1024, out_features=512, bias=True)\n",
       "    (dropout): Dropout(p=0.5)\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (attention): Attention(\n",
       "      (attn): Linear(in_features=1536, out_features=512, bias=True)\n",
       "    )\n",
       "    (embedding): Embedding(5893, 256)\n",
       "    (rnn): GRU(1280, 512)\n",
       "    (out): Linear(in_features=1792, out_features=5893, bias=True)\n",
       "    (dropout): Dropout(p=0.5)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def init_weights(m):\n",
    "    for name, param in m.named_parameters():\n",
    "        if 'weight' in name:\n",
    "            nn.init.normal_(param.data, mean=0, std=0.01)\n",
    "        else:\n",
    "            nn.init.constant_(param.data, 0)\n",
    "            \n",
    "model.apply(init_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dNpx8D7bKXf-"
   },
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MvQzXYaBc7E_"
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss(ignore_index = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9ejMfHYJc9io"
   },
   "outputs": [],
   "source": [
    "def train(model, batches, optimizer, criterion, clip):\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    \n",
    "    for i, b in enumerate(batches):\n",
    "        if i%100 == 0: \n",
    "            print( \"batch:\", i, \",\", torch.cuda.memory_allocated(device)/1e6, \"MB used\") \n",
    "\n",
    "        source = b['source']\n",
    "        target = b['target']\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = model(source, target)\n",
    "        \n",
    "        #trg = [trg sent len, batch size]\n",
    "        #output = [trg sent len, batch size, output dim]\n",
    "        \n",
    "        output = output[1:].view(-1, output.shape[-1])\n",
    "        target = target[1:].view(-1)\n",
    "        \n",
    "        #trg = [(trg sent len - 1) * batch size]\n",
    "        #output = [(trg sent len - 1) * batch size, output dim]\n",
    "        \n",
    "        loss = criterion(output, target)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        \n",
    "    return epoch_loss / len(batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2oEh9PRNc_Dg"
   },
   "outputs": [],
   "source": [
    "def evaluate(model, batches, criterion):\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "    \n",
    "        for i, b in enumerate(batches):\n",
    "            \n",
    "            source = b['source']\n",
    "            target = b['target']\n",
    "\n",
    "            output = model(source, target, 0) #turn off teacher forcing\n",
    "\n",
    "            #trg = [trg sent len, batch size]\n",
    "            #output = [trg sent len, batch size, output dim]\n",
    "\n",
    "            output = output[1:].view(-1, output.shape[-1])\n",
    "            target = target[1:].view(-1)\n",
    "\n",
    "            #trg = [(trg sent len - 1) * batch size]\n",
    "            #output = [(trg sent len - 1) * batch size, output dim]\n",
    "\n",
    "            loss = criterion(output, target)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "        \n",
    "    return epoch_loss / len(batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_lzhbb9ZKY8t"
   },
   "outputs": [],
   "source": [
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1207
    },
    "colab_type": "code",
    "id": "s47vhEzbEul5",
    "outputId": "9589143f-cd27-45c3-9627-859ae956ae96"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baking batches...\n",
      "Done.\n",
      "batch: 0 , 305.083392 MB used\n",
      "batch: 100 , 1219.593728 MB used\n",
      "Epoch: 01 | Time: 1m 23s\n",
      "\tTrain Loss: 6.734 | Train PPL: 840.499\n",
      "\t Val. Loss: 7.226 |  Val. PPL: 1375.229\n",
      "Baking batches...\n",
      "Done.\n",
      "batch: 0 , 1214.748672 MB used\n",
      "batch: 100 , 1219.72992 MB used\n",
      "Epoch: 02 | Time: 1m 24s\n",
      "\tTrain Loss: 5.903 | Train PPL: 366.096\n",
      "\t Val. Loss: 7.114 |  Val. PPL: 1228.948\n",
      "Baking batches...\n",
      "Done.\n",
      "batch: 0 , 1214.7456 MB used\n",
      "batch: 100 , 1219.595776 MB used\n",
      "Epoch: 03 | Time: 1m 25s\n",
      "\tTrain Loss: 5.399 | Train PPL: 221.237\n",
      "\t Val. Loss: 7.285 |  Val. PPL: 1458.989\n",
      "Baking batches...\n",
      "Done.\n",
      "batch: 0 , 1214.743552 MB used\n",
      "batch: 100 , 1219.593728 MB used\n",
      "Epoch: 04 | Time: 1m 24s\n",
      "\tTrain Loss: 4.907 | Train PPL: 135.293\n",
      "\t Val. Loss: 7.175 |  Val. PPL: 1306.044\n",
      "Baking batches...\n",
      "Done.\n",
      "batch: 0 , 1214.736896 MB used\n",
      "batch: 100 , 1219.587072 MB used\n",
      "Epoch: 05 | Time: 1m 24s\n",
      "\tTrain Loss: 4.434 | Train PPL:  84.267\n",
      "\t Val. Loss: 7.197 |  Val. PPL: 1334.802\n",
      "Baking batches...\n",
      "Done.\n",
      "batch: 0 , 1214.736896 MB used\n",
      "batch: 100 , 1219.587072 MB used\n",
      "Epoch: 06 | Time: 1m 24s\n",
      "\tTrain Loss: 4.196 | Train PPL:  66.426\n",
      "\t Val. Loss: 7.381 |  Val. PPL: 1605.362\n",
      "Baking batches...\n",
      "Done.\n",
      "batch: 0 , 1214.740992 MB used\n",
      "batch: 100 , 1219.591168 MB used\n",
      "Epoch: 07 | Time: 1m 25s\n",
      "\tTrain Loss: 3.897 | Train PPL:  49.267\n",
      "\t Val. Loss: 7.257 |  Val. PPL: 1418.629\n",
      "Baking batches...\n",
      "Done.\n",
      "batch: 0 , 1214.730752 MB used\n",
      "batch: 100 , 1219.712 MB used\n",
      "Epoch: 08 | Time: 1m 24s\n",
      "\tTrain Loss: 3.749 | Train PPL:  42.465\n",
      "\t Val. Loss: 7.189 |  Val. PPL: 1324.262\n",
      "Baking batches...\n",
      "Done.\n",
      "batch: 0 , 1214.735872 MB used\n",
      "batch: 100 , 1219.586048 MB used\n",
      "Epoch: 09 | Time: 1m 24s\n",
      "\tTrain Loss: 3.567 | Train PPL:  35.401\n",
      "\t Val. Loss: 7.197 |  Val. PPL: 1335.578\n",
      "Baking batches...\n",
      "Done.\n",
      "batch: 0 , 1214.741504 MB used\n",
      "batch: 100 , 1219.59168 MB used\n",
      "Epoch: 10 | Time: 1m 24s\n",
      "\tTrain Loss: 3.487 | Train PPL:  32.672\n",
      "\t Val. Loss: 7.539 |  Val. PPL: 1879.236\n"
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 10\n",
    "CLIP = 1\n",
    "\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    random.shuffle(training_data)\n",
    "    random.shuffle(validation_data)\n",
    "\n",
    "    de_shuffled_td = [td[0] for td in training_data]\n",
    "    en_shuffled_td = [td[1] for td in training_data]\n",
    "    \n",
    "    de_shuffled_vd = [vd[0] for vd in validation_data]\n",
    "    en_shuffled_vd = [vd[1] for vd in validation_data]\n",
    "    \n",
    "    print(\"Baking batches...\")\n",
    "    train_batches = bake_batches(de_shuffled_td, en_shuffled_td, max_len=max_len_train)\n",
    "    valid_batches = bake_batches(de_shuffled_vd, en_shuffled_vd, max_len=max_len_valid)\n",
    "    print(\"Done.\")\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    train_loss = train(model, train_batches, optimizer, criterion, CLIP)\n",
    "    valid_loss = evaluate(model, valid_batches, criterion)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    \n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    \n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'tut3-model.pt')\n",
    "    \n",
    "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iVBVUJ2qRb3w"
   },
   "outputs": [],
   "source": [
    "results_test_a = {}\n",
    "results_test_b = {}\n",
    "\n",
    "results_test_a['train_loss'] = [4.951, 4.208, 3.919, 3.738, 3.631, 3.566, 3.511     ]\n",
    "results_test_a['valid_loss'] = [5.028, 4.961, 5.049, 5.060, 5.087, 5.102, 5.142    ]\n",
    "results_test_a['train_ppl'] = [141.283, 67.240, 50.341, 42.028, 37.761, 35.362, 33.467]\n",
    "results_test_a['valid_ppl'] = [152.631, 142.753, 155.863, 157.552, 161.846, 164.395, 171.068]\n",
    "\n",
    "results_test_b['train_loss'] = [4.945,  4.226, 3.940, 3.759, 3.651, 3.587, 3.536]\n",
    "results_test_b['valid_loss'] = [5.310, 5.215, 5.187, 5.247, 5.323, 5.303, 5.368]\n",
    "results_test_b['train_ppl'] = [140.527,  68.470, 51.401, 42.904, 38.516, 36.116, 34.334]\n",
    "results_test_b['valid_ppl'] = [202.433, 183.977, 178.941, 189.977, 204.979, 200.840, 214.369]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nVMwmNCCLH3W"
   },
   "outputs": [],
   "source": [
    "def sample_net(net, batches):    \n",
    "    preds = []\n",
    "    targets = []\n",
    "    sources = []\n",
    "    sampled_batches = {}\n",
    "       \n",
    "    with torch.no_grad():\n",
    "        for b in batches:\n",
    "            source = b['source']\n",
    "            target = b['target']\n",
    "            \n",
    "#             print(\"L length x N sentences:\", target.shape)\n",
    "        \n",
    "            output = net.forward(source, target, teacher_forcing_ratio=0)\n",
    "            \n",
    "#             print(\"L length x N sentences x V vocabulary:\", output.shape)\n",
    "            \n",
    "#             pred = torch.softmax(output, dim=2)\n",
    "\n",
    "#             print(\"L length x N sentences x V vocabulary:\", pred.shape)\n",
    "            \n",
    "            pred = torch.argmax(output, dim=2)\n",
    "            \n",
    "#             print(\"L length x N sentences:\", pred.shape)\n",
    "#             print(\"L length x N sentences:\", target.shape)\n",
    "            \n",
    "            preds.append(pred)\n",
    "            targets.append(target)\n",
    "            sources.append(source)\n",
    "    \n",
    "    sampled_batches['source'] = sources\n",
    "    sampled_batches['target'] = targets\n",
    "    sampled_batches['prediction'] = preds\n",
    "    \n",
    "    return sampled_batches\n",
    "\n",
    "\n",
    "batches = bake_batches(german['dev'], english['dev'])\n",
    "sampled_batches = sample_net(model, batches)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dpver7T0LIDe"
   },
   "outputs": [],
   "source": [
    "def print_samples(batches):\n",
    "    # Each of the inputs should be a tensor batch of shape L x N\n",
    "    # print(sources.shape)\n",
    "\n",
    "    source = batches['source']\n",
    "    target = batches['target']\n",
    "    prediction = batches['prediction']\n",
    "    \n",
    "    \n",
    "    tgt_out = []\n",
    "    pred_out = []\n",
    "    for b in range(len(batches['source'])):\n",
    "        for sent in range(source[b].shape[1]):\n",
    "#             w = 1\n",
    "#             idx = source[b][w,sent].item()\n",
    "#             print(\"Source Sentence:\")\n",
    "#             while w < source[b][:,sent].shape[0] and idx!=3: \n",
    "#                 print(german['idx2word'][idx], end=\" \")\n",
    "#                 idx = source[b][w,sent].item()\n",
    "#                 w+=1\n",
    "            \n",
    "            w = 1\n",
    "            idx = target[b][w,sent].item()\n",
    "            tgt_sent = []\n",
    "#             print(\"\\nTarget Sentence:\")\n",
    "            while w < target[b][:,sent].shape[0] and idx!=3:\n",
    "#                 print(english['idx2word'][idx], end=\" \")\n",
    "                tgt_sent.append(english['idx2word'][idx])\n",
    "                idx = target[b][w,sent].item()\n",
    "                w+=1\n",
    "            tgt_out.append(tgt_sent)\n",
    "\n",
    "\n",
    "            w = 1\n",
    "            idx = prediction[b][w,sent].item()\n",
    "            pred_sent = []\n",
    "#             print(\"\\nPrediction:\")\n",
    "            while w < prediction[b][:,sent].shape[0] and idx!=3:\n",
    "#                 print(english['idx2word'][idx], end=\" \")\n",
    "                pred_sent.append(english['idx2word'][idx])\n",
    "                idx = prediction[b][w,sent].item()\n",
    "                w+=1\n",
    "            pred_out.append(pred_sent)\n",
    "\n",
    "#             print(\"\\n\")\n",
    "            \n",
    "    with open('target.out', 'w') as f:\n",
    "        for sent in tgt_out:\n",
    "            x = \" \".join(sent)\n",
    "            f.write(x + '\\n')\n",
    "            \n",
    "            \n",
    "    with open('pred.out', 'w') as f:\n",
    "        for sent in pred_out:\n",
    "            y = \" \".join(sent)\n",
    "            f.write(y + '\\n')\n",
    "\n",
    "print_samples(sampled_batches)\n",
    "    \n",
    "# print(pred[0])\n",
    "# print(target[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "drtkoM5qe9y1",
    "outputId": "fb117a6a-3cfd-4010-c08d-9bdf9c048562"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'mosesdecoder' already exists and is not an empty directory.\n",
      "Requirement already satisfied: sacrebleu in /usr/local/lib/python3.6/dist-packages (1.3.2)\n",
      "Requirement already satisfied: typing in /usr/local/lib/python3.6/dist-packages (from sacrebleu) (3.6.6)\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/moses-smt/mosesdecoder.git\n",
    "!pip install sacrebleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "colab_type": "code",
    "id": "muT6lj3tVLPF",
    "outputId": "62a02b75-391d-4a1e-dbea-56f00a96393f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detokenizer Version $Revision: 4134 $\n",
      "Language: en\n",
      "BLEU+case.mixed+lang.de-en+numrefs.1+smooth.exp+tok.intl+version.1.3.2 = 3.4 21.6/6.3/1.8/0.5 (BP = 1.000 ratio = 1.304 hyp_len = 14328 ref_len = 10991)\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 21,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%shell\n",
    "#!/bin/bash\n",
    "\n",
    "# This is a reference to the gold translations from the dev set\n",
    "REFERENCE_FILE=\"target.out\"\n",
    "\n",
    "# XXX: Change the following line to point to your model's output!\n",
    "TRANSLATED_FILE=\"pred.out\"\n",
    "\n",
    "# The model output is expected to be in a tokenized form. Note, that if you\n",
    "# tokenized your inputs to the model, then simply joined each output token with\n",
    "# whitespace you should get tokenized outputs from your model.\n",
    "# i.e. each output token is separate by whitespace\n",
    "# e.g. \"My model 's output is interesting .\"\n",
    "perl \"mosesdecoder/scripts/tokenizer/detokenizer.perl\" -l en < \"$TRANSLATED_FILE\" > \"$TRANSLATED_FILE.detok\"\n",
    "\n",
    "PARAMS=(\"-tok\" \"intl\" \"-l\" \"de-en\" \"$REFERENCE_FILE\")\n",
    "sacrebleu \"${PARAMS[@]}\" < \"$TRANSLATED_FILE.detok\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ogYzCtIcUZH4"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Final Project.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
